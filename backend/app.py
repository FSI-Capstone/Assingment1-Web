from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
from openai import OpenAI
from dotenv import load_dotenv
import os
import re
from pathlib import Path
import csv
import io

load_dotenv()

app = Flask(__name__)
CORS(app)

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ë¬¸ì œ ìœ í˜• ì„¤ëª… ë§¤í•‘
QUESTION_TYPE_DESCRIPTIONS = {
    "ê¸°ë³¸ ì •ë³´ í™•ì¸": "ì •ë³´ ë˜ëŠ” ì •ì˜ë¥¼ ë¬»ëŠ” ì •í˜•í™”ëœ ë¬¸ì œ",
    "ë¹ˆì¹¸ ì±„ìš°ê¸°": "ë‚´ í•µì‹¬ ê°œë…ì„ ë¹ˆì¹¸ìœ¼ë¡œ ì œì‹œ, ì•Œë§ì€ ë‹¨ì–´ë‚˜ ê°œë… ì„ íƒí•˜ëŠ” ë¬¸ì œ",
    "ì‚¬ë¡€/ì‹œë‚˜ë¦¬ì˜¤": "ìƒí™©ì„ ê°„ë‹¨íˆ ì„¤ëª…í•˜ê³ , ì˜¬ë°”ë¥¸ ëŒ€ì²˜ë²•ì´ë‚˜ íŒë‹¨ì„ ë¬»ëŠ” ë¬¸ì œ",
    "ì¼ì¹˜ ì—¬ë¶€ íŒë‹¨": "ì„¤ëª…ì´ ì£¼ì–´ì§„ ë’¤, ê´€ë ¨ ì •ë³´ ì¤‘ ì˜¬ë°”ë¥¸ ê²ƒì„ ì„ íƒí•˜ëŠ” ë¬¸ì œ",
    "ì›ì¸-ê²°ê³¼ ì—°ê²°": "í˜„ìƒì˜ ì›ì¸ ë˜ëŠ” ê²°ê³¼ë¥¼ ë¬»ëŠ” ë¬¸ì œ",
    "ìš°ì„ ìˆœìœ„/ì ˆì°¨": "ë‹¨ê³„ê°€ ìˆëŠ” ì ˆì°¨ ì¤‘, ê°€ì¥ ë¨¼ì € í˜¹ì€ ì˜¬ë°”ë¥¸ ìˆœì„œë¥¼ ë¬»ëŠ” ë¬¸ì œ",
    "í‹€ë¦° ê²ƒ ê³ ë¥´ê¸°": "ë³´ê¸° ì¤‘ í‹€ë¦° ì •ë³´ë¥¼ ì„ íƒí•˜ëŠ” ë¬¸ì œ",
    "ë¹„êµ/êµ¬ë¶„": "ê°œë…ì´ë‚˜ ê¸°ìˆ ì„ êµ¬ë³„í•˜ê±°ë‚˜ ë¹„êµí•˜ëŠ” ë¬¸ì œ",
    "ì ìš© íŒë‹¨": "ì§€ì¹¨/ë³´ì•ˆìˆ˜ì¹™ ë“±ì„ íŠ¹ì • ìƒí™©ì— ì ìš©í•  ìˆ˜ ìˆëŠ”ì§€ ë¬»ëŠ” ë¬¸ì œ"
}

# ì¶œì œê¸°ì¤€ ê°€ì´ë“œ ë¶ˆëŸ¬ì˜¤ê¸°
def load_guide_content(domain):
    base_path = Path(__file__).parent / "guides"
    guide_files = {
        "ì¼ë°˜": "general.md",
        "IT": "it.md",
        "ë²•ë¥ ": "law.md",
        "ë™í–¥": "trend.md"
    }

    try:
        file_path = base_path / guide_files[domain]
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        return f"âŒ ê°€ì´ë“œ ë¡œë”© ì˜¤ë¥˜: {str(e)}"

@app.route("/generate", methods=["POST"])
def generate():
    data = request.get_json()
    question_type = data.get("question_type", "ê¸°ë³¸ ì •ë³´ í™•ì¸")
    domain = data.get("domain", "ì¼ë°˜")
    num_questions = int(data.get("num_questions", 1))
    difficulty = data.get("difficulty", "ì¤‘")
    include_explanation = data.get("include_explanation", True)
    output_format = data.get("output_format", "Plain Text")
    main_criteria = data.get("mainCriteria", "")
    sub_criteria = data.get("subCriteria", "")
    detail_criteria = data.get("detailCriteria", "")

    question_type_desc = QUESTION_TYPE_DESCRIPTIONS.get(question_type, "")
    guide_content = load_guide_content(domain)  # ğŸ”§ ë„ë©”ì¸ë³„ ê°€ì´ë“œ ë¡œë”©

    if guide_content.startswith("âŒ"):
        return jsonify({"error": guide_content}), 500

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""
ë‹¹ì‹ ì€ ê¸ˆìœµë³´ì•ˆ êµìœ¡ìš© ë¬¸ì œë¥¼ ì¶œì œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì¡°ê±´ì— ë”°ë¼ ë¬¸ì œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:
ë¹ˆ ë°°ì—´ì€ ì ˆëŒ€ ë°˜í™˜í•˜ì§€ ë§ˆì„¸ìš”.

1. ë¬¸ì œ ìœ í˜•: {question_type}
   - ìœ í˜• ì„¤ëª…: {question_type_desc}
2. ë„ë©”ì¸: {domain}
3. ë‚œì´ë„: {difficulty}
4. ë¬¸ì œ ìˆ˜: {num_questions}ê°œ
5. ì¶œë ¥ í˜•ì‹: {output_format}
6. ì¶œì œê¸°ì¤€: {main_criteria} > {sub_criteria} > {detail_criteria}

ê° ë¬¸ì œëŠ” 5ì§€ì„ ë‹¤ë¡œ ë‹¤ìŒ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¼ì£¼ì„¸ìš”:

[ë¬¸ì œ í˜•ì‹]
- ì¶œì œ ê¸°ì¤€: {main_criteria}> {sub_criteria} > {detail_criteria} í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
- ë¬¸ì œ ë²ˆí˜¸ì™€ ë‚´ìš© (ë°˜ë“œì‹œ ìœ„ì—ì„œ ì„¤ëª…í•œ ë¬¸ì œ ìœ í˜•ì˜ íŠ¹ì„±ì„ ì •í™•íˆ ë°˜ì˜í•´ì•¼ í•¨)
- ë³´ê¸°

[í•´ë‹µ]
- ì •ë‹µ
{f'- í•´ì„¤ (ë¬¸ì œ ìœ í˜•ì˜ íŠ¹ì„±ì— ë§ì¶° ìƒì„¸íˆ ì„¤ëª…)' if include_explanation else ''}

ë¬¸ì œì™€ í•´ë‹µì€ "[í•´ë‹µ]" êµ¬ë¶„ìë¡œ êµ¬ë¶„í•˜ê³ , ê° ë¬¸ì œëŠ” "---" êµ¬ë¶„ìë¡œ êµ¬ë¶„í•´ì£¼ì„¸ìš”.
ë¬¸ì œë“¤ì€ ì„œë¡œ ì¤‘ë³µë˜ì§€ ì•Šì•„ì•¼ í•˜ë©°, ëª…í™•í•˜ê³  ì •í™•í•œ ë‚´ìš©ì„ ë‹´ê³  ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
ê° ë¬¸ì œë§ˆë‹¤ ìœ„ì˜ ì¶œì œ ê¸°ì¤€ ì¤‘ì—ì„œ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ ë°˜ë“œì‹œ ëª…ì‹œí•´ì£¼ì„¸ìš”.
íŠ¹íˆ, ì„ íƒí•œ ë¬¸ì œ ìœ í˜•ì˜ íŠ¹ì„±ì„ ì •í™•íˆ ë°˜ì˜í•˜ì—¬ ë¬¸ì œë¥¼ ì¶œì œí•´ì£¼ì„¸ìš”.
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ê¸ˆìœµë³´ì•ˆ ë¬¸ì œ ì¶œì œìì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.0,
            max_tokens=2000
        )
        result = response.choices[0].message.content
        print("ğŸ“¤ GPT ì‘ë‹µ ì›ë¬¸:\n", result)
        questions = parse_response(result)

        if output_format == "CSV":
            # Create CSV data
            csv_output = io.StringIO()
            csv_writer = csv.writer(csv_output)
            csv_writer.writerow(["ë²ˆí˜¸", "ì¶œì œê¸°ì¤€", "ë¬¸ì œ", "í•´ë‹µ"])
            for idx, qa in enumerate(questions, start=1):
                csv_writer.writerow([idx, f"{main_criteria} > {sub_criteria} > {detail_criteria}", qa["question"], qa["answer"]])
            csv_output.seek(0)
            return send_file(io.BytesIO(csv_output.getvalue().encode('utf-8')), mimetype='text/csv', as_attachment=True, download_name='questions.csv')

        return jsonify({"questions": questions})
    except Exception as e:
        import traceback
        print("âŒ GPT í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:\n", traceback.format_exc())
        return jsonify({"error": str(e)}), 500


def parse_response(content):
    questions_and_answers = []
    raw_questions = re.split(r"\n-{3,}\n", content.strip())

    for raw in raw_questions:
        parts = re.split(r"\n*\[í•´ë‹µ\]|\n*í•´ë‹µ\n*|\n*í•´ë‹µ:\n*", raw)
        if len(parts) == 2:
            question = parts[0].strip()
            answer = parts[1].strip()

            if not question:
                print("âš ï¸ ì§ˆë¬¸ ëˆ„ë½ë¨:", raw[:200])
                continue

            questions_and_answers.append({
                "question": question,
                "answer": answer
            })
        else:
            print("âš ï¸ íŒŒì‹± ì‹¤íŒ¨:", raw[:200])
    return questions_and_answers

# New endpoint to download CSV file
@app.route("/download_csv", methods=["GET"])
def download_csv():
    # This endpoint can be used if CSV is pre-generated and stored
    return send_file("path_to_csv_file.csv", mimetype='text/csv', as_attachment=True, attachment_filename='questions.csv')

if __name__ == "__main__":
    app.run(debug=True, port=5000)
